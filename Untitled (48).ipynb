{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd947063-462c-4e23-a6d2-5f1777fc73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?\n",
    "ANS-The main difference between Euclidean distance and Manhattan distance metrics is how they measure the distance between two points in a multi-dimensional space.\n",
    "\n",
    "Euclidean distance is the straight-line distance between two points in Euclidean space. In other words, it measures the shortest distance between two points in a straight line. Mathematically, the Euclidean distance between two points A and B can be computed as the square root of the sum of the squared differences between their corresponding coordinates:\n",
    "\n",
    "scss\n",
    "Copy code\n",
    "Euclidean distance = sqrt((x1-x2)^2 + (y1-y2)^2 + ... + (n1-n2)^2)\n",
    "On the other hand, the Manhattan distance (also known as the taxicab or city block distance) is the distance between two points measured along the axes at right angles. In other words, it measures the distance between two points by summing the absolute differences of their corresponding coordinates. Mathematically, the Manhattan distance between two points A and B can be computed as:\n",
    "\n",
    "java\n",
    "Copy code\n",
    "Manhattan distance = |x1-x2| + |y1-y2| + ... + |n1-n2|\n",
    "The choice between these distance metrics can affect the performance of a KNN classifier or regressor, depending on the nature of the dataset and the problem at hand. In general, the Euclidean distance metric is better suited for datasets with continuous features and where the concept of distance is based on geometric similarity. The Manhattan distance metric, on the other hand, is better suited for datasets with discrete features and where the concept of distance is based on movement along a grid or city blocks.\n",
    "\n",
    "In some cases, using the wrong distance metric can lead to suboptimal performance of a KNN classifier or regressor. For example, if the data is arranged in a grid-like pattern, the Manhattan distance may be a more appropriate choice. Conversely, if the data is arranged in a circular or spherical pattern, the Euclidean distance may be more appropriate. In practice, it's often a good idea to experiment with different distance metrics to find the one that works best for a given problem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c7ca4-fd63-4e81-b804-e62f85079626",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?\n",
    "ANS-The value of k in K-Nearest Neighbors (KNN) algorithm plays a crucial role in determining the accuracy and generalization of the model. Choosing an optimal value of k is important as selecting an inappropriate value may lead to underfitting or overfitting.\n",
    "\n",
    "One way to determine the optimal k value is by performing a grid search over a range of k values and selecting the value that results in the highest accuracy or lowest error. This approach is computationally expensive and may not be feasible for large datasets or higher dimensions.\n",
    "\n",
    "Another way is to use cross-validation techniques such as k-fold cross-validation, where the data is divided into k subsets, and the model is trained and tested on each fold. The average accuracy or error across all folds is used to evaluate the performance of the model for each k value. The k value that gives the best performance can be chosen as the optimal value.\n",
    "\n",
    "Additionally, a plot of k versus the model's performance metric can be used to visualize the relationship between k and performance. For classification tasks, the accuracy or F1-score can be used, while for regression tasks, mean squared error or R-squared can be used.\n",
    "\n",
    "It is important to note that the optimal k value may vary based on the dataset and problem at hand. Therefore, it is recommended to experiment with different values of k and evaluate the model's performance to select the optimal value.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb57fa-efa3-492c-ab79-4520a444254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?\n",
    "ans-The choice of distance metric can have a significant impact on the performance of a KNN classifier or regressor, depending on the nature of the data and the problem being solved. Different distance metrics may result in different classifications or regression predictions for the same input data, as they measure the similarity or distance between data points in different ways.\n",
    "\n",
    "For example, the Euclidean distance metric is commonly used in KNN algorithms because it assumes that the data is arranged in a geometric space and measures the straight-line distance between data points. It is suitable for continuous or numerical data and is sensitive to the scale of the data. When the data is normalized, the Euclidean distance metric can work well for most applications.\n",
    "\n",
    "On the other hand, the Manhattan distance metric may be more appropriate for categorical or discrete data, where it measures the distance between data points along the axes of the data grid. It is insensitive to the scale of the data and can work better than the Euclidean distance metric when the data is not normalized.\n",
    "\n",
    "In some cases, neither the Euclidean nor the Manhattan distance metric may be appropriate. For example, in text classification problems, the cosine similarity metric is often used to measure the distance between documents.\n",
    "\n",
    "In general, the choice of distance metric depends on the nature of the data and the problem being solved. One should consider the scale and type of features, as well as the potential non-linear relationships between features. It is often a good idea to experiment with different distance metrics to see which one works best for a given problem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9030cc-87e0-4cf4-bcdf-31438ce45528",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?\n",
    "anss-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049a015-54ae-46b3-9b08-9c426dd52d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526f744-8d46-414a-8975-8cd9cad1a37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13069a-f7dd-4486-abf0-a9468dc179ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98299a34-62b1-4cdf-a173-c4a501a0f7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c4e70-a939-4300-a741-d6e7ff1917a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
